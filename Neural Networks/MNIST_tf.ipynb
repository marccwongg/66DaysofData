{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "import tensorflow_datasets as tfds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#load dataset from packages\r\n",
    "mnist_ds, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Pre-processing\r\n",
    "#split train and test sample data\r\n",
    "mnist_train, mnist_test = mnist_ds['train'], mnist_ds['test']\r\n",
    "\r\n",
    "#store train samples\r\n",
    "n_valid_samples = 0.1 * mnist_info.splits['train'].num_examples\r\n",
    "n_valid_samples = tf.cast(n_valid_samples, tf.int64) #cast variable to an int\r\n",
    "\r\n",
    "#store test samples\r\n",
    "n_test_samples = 0.1 * mnist_info.splits['test'].num_examples\r\n",
    "n_test_samples = tf.cast(n_test_samples, tf.int64) #cast variable to an int\r\n",
    "\r\n",
    "#scaling data\r\n",
    "def scale(image, label):\r\n",
    "    image = tf.cast(image, tf.float32) #cast image to float\r\n",
    "    image /= 255.\r\n",
    "    return image, label\r\n",
    "\r\n",
    "scaled_train_valid_data = mnist_train.map(scale)\r\n",
    "test_data = mnist_test.map(scale)\r\n",
    "\r\n",
    "BUFFER_SIZE = 10000 #batches to be shuffled at intervals\r\n",
    "\r\n",
    "shuffled_train_valid_data = scaled_train_valid_data.shuffle(BUFFER_SIZE)\r\n",
    "\r\n",
    "valid_data = shuffled_train_valid_data.take(n_valid_samples)\r\n",
    "train_data = shuffled_train_valid_data.skip(n_valid_samples)\r\n",
    "\r\n",
    "BATCH_SIZE = 100 #batch size for mini batch GD\r\n",
    "\r\n",
    "train_data= train_data.batch(BATCH_SIZE)\r\n",
    "valid_data = valid_data.batch(n_valid_samples) #overwrite with whole size of valid data\r\n",
    "test_data = test_data.batch(n_test_samples)\r\n",
    "\r\n",
    "valid_inputs, valid_targets = next(iter(valid_data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Outlining the model\r\n",
    "#set hyperparameters\r\n",
    "\r\n",
    "input_size = 784\r\n",
    "output_size = 10\r\n",
    "hiddenlayer_size = 100\r\n",
    "\r\n",
    "#Specifying Layers\r\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28,28,1)),\r\n",
    "                             tf.keras.layers.Dense(hiddenlayer_size,activation='relu'), #first hidden layer\r\n",
    "                             tf.keras.layers.Dense(hiddenlayer_size,activation='relu'), #second hidden layer\r\n",
    "                             tf.keras.layers.Dense(output_size,activation='softmax') #output layer\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Choose optimizer and loss fucntion\r\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Model training\r\n",
    "N_EPOCHS = 5\r\n",
    "\r\n",
    "model.fit(train_data, epochs= N_EPOCHS, validation_data=(valid_inputs, valid_targets), verbose=2)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 3s - loss: 0.3419 - accuracy: 0.9029 - val_loss: 0.1796 - val_accuracy: 0.9465\n",
      "Epoch 2/5\n",
      "540/540 - 2s - loss: 0.1420 - accuracy: 0.9577 - val_loss: 0.1222 - val_accuracy: 0.9627\n",
      "Epoch 3/5\n",
      "540/540 - 3s - loss: 0.0985 - accuracy: 0.9705 - val_loss: 0.0972 - val_accuracy: 0.9703\n",
      "Epoch 4/5\n",
      "540/540 - 3s - loss: 0.0735 - accuracy: 0.9780 - val_loss: 0.0817 - val_accuracy: 0.9757\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.0593 - accuracy: 0.9811 - val_loss: 0.0627 - val_accuracy: 0.9798\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x180b4b06ca0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Testing the model\r\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10/10 [==============================] - 1s 69ms/step - loss: 0.0868 - accuracy: 0.9732\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print('Test Loss: {0:.2f} // Test Accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Loss: 0.09 // Test Accuracy: 97.32%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('py3-TF25': conda)"
  },
  "interpreter": {
   "hash": "e86511d5626f5a70a06cf43a1b1550634341a3f70e0e358501a2d4688d14c472"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}